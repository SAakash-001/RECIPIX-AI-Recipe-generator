{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762b2beb-5546-498c-8ee3-0554870f38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b024c20d-2a4f-493b-be7f-6d3a9bc34d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + ws[1], x: x + ws[0]])\n",
    "\n",
    "def image_pyramid(image, scale=1.5, min_size=(224, 224)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "\n",
    "    # keep looping over the image pyramid\n",
    "    while True:\n",
    "        # compute the dimensions of the next image in the pyramid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "\n",
    "        # if the resized image does not meet the supplied minimum size, then stop constructing the pyramid\n",
    "        if image.shape[0] < min_size[1] or image.shape[1] < min_size[0]:\n",
    "            break\n",
    "\n",
    "        # yield the next image in the pyramid\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2417ced-0f9e-4a88-aa0d-c21d1c3c8d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load your model\n",
    "model_path = 'C:/Users/Lenovo/Videos/Project/RECIPE GENERATOR/Jupyter/mobileNet.h5'\n",
    "vegetable_model = load_model(model_path)\n",
    "\n",
    "# Your image path\n",
    "img_path = 'C:/Users/Lenovo/Videos/Project/RECIPE GENERATOR/Jupyter/test_image.jpg'\n",
    "orig = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163315e4-c9bc-46cb-b80f-2ac7f549a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes : 26 /nClass Names : ['BEAN', 'BEETROOT', 'BITTER GOURD', 'BOTTLE GOURD', 'CABBAGE', 'CAPSICUM', 'CARROT', 'CAULIFLOWER', 'CHILLI', 'CORN', 'CUCUMBER', 'EGG', 'EGGPLANT', 'GARLIC', 'GINGER', 'LEMON', 'LETTUCE', 'OKRA', 'ONION', 'PEAS', 'POTATO', 'PUMPKIN', 'RADDISH', 'SPINACH', 'TOMATO', 'TURNIP']\n"
     ]
    }
   ],
   "source": [
    "# Class Names\n",
    "root_path = 'C:/Users/Lenovo/Videos/Project/RECIPE GENERATOR/Jupyter/split_refined_data/train/'\n",
    "class_names = sorted(os.listdir(root_path))\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Class Distribution\n",
    "class_dis = [len(os.listdir(root_path + name)) for name in class_names]\n",
    "\n",
    "\n",
    "# Show\n",
    "print(f\"Total Number of Classes : {n_classes} /nClass Names : {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf90a6b6-652d-4ebe-b3f9-6c927ef387b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 261ms/step\n",
      "Detected Vegetable Names: ['CUCUMBER', 'EGGPLANT']\n",
      "Output image saved at: C:/Users/Lenovo/Videos/Project/RECIPE GENERATOR/Jupyter/detected_objects.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Set parameters\n",
    "MIN_CONFIDENCE = 0.95  # Adjust this threshold as needed\n",
    "WIDTH = 900\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 8\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "# initialize the image pyramid\n",
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, min_size=INPUT_SIZE)\n",
    "\n",
    "# initialize two lists, one to hold the ROIs generated from the image pyramid and sliding window,\n",
    "# and another list used to store the (x,y)-coordinate of where the ROI was in the original image\n",
    "rois = []\n",
    "locs = []\n",
    "\n",
    "# loop over the image pyramid\n",
    "for image in pyramid:\n",
    "    # for each layer of the image pyramid, loop over the sliding window locations\n",
    "    for (x, y, roi_orig) in sliding_window(image, WIN_STEP, INPUT_SIZE):\n",
    "        # randomly change the size of the bounding box within a specified range\n",
    "        roi_size = (\n",
    "            random.randint(50, 200),  # random width between 100 and 200 pixels\n",
    "            random.randint(50, 200),   # random height between 75 and 150 pixels\n",
    "        )\n",
    "\n",
    "        # take the ROI and pre-process it so we can later classify the region using Keras/Tensorflow\n",
    "        roi = cv2.resize(roi_orig, (224, 224))  # Resize to a fixed size\n",
    "        roi = img_to_array(roi)\n",
    "        roi = preprocess_input(roi)\n",
    "\n",
    "        # update our list of ROIs and associated coordinates\n",
    "        rois.append(roi)\n",
    "        locs.append((x, y, x + roi_size[0], y + roi_size[1]))\n",
    "\n",
    "# convert and ROIs to a Numpy array\n",
    "rois = np.array(rois, dtype='float32')\n",
    "\n",
    "# classify each of the proposal ROIs using your model\n",
    "predictions = vegetable_model.predict(rois)\n",
    "\n",
    "# initialize the list to store detected vegetables\n",
    "detected_vegetables = []\n",
    "\n",
    "# initialize a set to keep track of unique detected vegetable names\n",
    "unique_vegetable_names = set()\n",
    "\n",
    "# Loop over the predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(pred)\n",
    "\n",
    "    # Get the class name\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "\n",
    "    # Get the confidence/probability score\n",
    "    confidence = pred[predicted_class_index]\n",
    "\n",
    "    # Filter out weak detections by ensuring the predicted probability is greater than the minimum probability\n",
    "    if confidence >= MIN_CONFIDENCE:\n",
    "        # Check if the vegetable name is not already present in the set\n",
    "        if predicted_class not in unique_vegetable_names:\n",
    "            # Add the detected vegetable to the list\n",
    "            detected_vegetables.append({\n",
    "                'class': predicted_class,\n",
    "                'confidence': confidence,\n",
    "                'box': locs[i]\n",
    "            })\n",
    "            \n",
    "            # Add the vegetable name to the set to avoid repetition\n",
    "            unique_vegetable_names.add(predicted_class)\n",
    "\n",
    "# Create a list of detected vegetable names\n",
    "detected_vegetable_names = [veg['class'] for veg in detected_vegetables]\n",
    "\n",
    "# Print the list of detected vegetable names\n",
    "print(\"Detected Vegetable Names:\", detected_vegetable_names)\n",
    "\n",
    "# # Print the list of detected vegetables\n",
    "# for veg in detected_vegetables:\n",
    "#     print(f\"Class: {veg['class']}, Confidence: {veg['confidence']}, Bounding Box: {veg['box']}\")\n",
    "\n",
    "# Draw bounding boxes on the original image for visualization\n",
    "clone = orig.copy()\n",
    "for veg in detected_vegetables:\n",
    "    (startX, startY, endX, endY) = veg['box']\n",
    "    cv2.rectangle(clone, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "# # Show the output after\n",
    "# cv2.imshow(\"Detected Vegetables\", clone)\n",
    "# cv2.waitKey(0)\n",
    "# Save the output image after drawing bounding boxes\n",
    "output_path = 'C:/Users/Lenovo/Videos/Project/RECIPE GENERATOR/Jupyter/detected_objects.jpg'\n",
    "cv2.imwrite(output_path, clone)\n",
    "print(f\"Output image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35dbbf-8ea4-4d04-8e28-a8fa2f2b3e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6952f15-397b-4b7b-996a-dccae07166b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
